{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pandas - partie 2\n",
    "\n",
    "<img src=\"https://pandas.pydata.org/docs/_static/pandas.svg\" alt=\"logo pandas\" width=\"500\"/>\n",
    "\n",
    "Dans la première partie, nous avons vous l'objet qui se trouve au coeur de la librairie pandas, cousine de numpy. Pour rappel, un dataset (ou jeu de données) et la donnée brute, on la transforme en DataFrame, objet qui ressemble à un tableau excel où chaque colonne possède un nom. Ainsi, il est dit que les données d'un DataFrame sont tabulaires.\n",
    "\n",
    "La partie 1 du TP pandas a été l'occasion de travailler avec de petits dataframes (écrits à la main), toutefois en Big Data, ce n'est pas des DataFrame de moins de 60 lignes avec lesquels nous travaillons, mais en général plus de 100 000. Bien évidemment, nous n'allons pas écrire à la main, ces gros fichiers. C'est ici qu'entre en jeu l'Open Data, notamment popularisé par le \"Florida Man\". L'Open Data ou Données Ouvertes permettent à tous de récupérer des données exposées par des gouvernements et autres institutions pour les exploiter. Ces données peuvent être sous plusieurs formes mais celle la plus courante est le format csv.\n",
    "\n",
    "Et ces données, on les trouve où ? Il existe beaucoup de sources, dans le cadre de cette pratique, nous allons utiliser celui des naissances de 1900 et 2020 par département (voir lien plus bas). Mais voici quelques sites :\n",
    "\n",
    "- [Voir site des données ouvertes du gouvernement](https://www.data.gouv.fr/)\n",
    "- [Voir site des données ouvertes de l'insee](https://www.insee.fr/fr/statistiques?categorie=1)\n",
    "- [Voir moteur de recherche de Google dédié aux datasets](https://datasetsearch.research.google.com/)\n",
    "- [Voir site des données ouvertes de l'éducation nationale](https://data.education.gouv.fr/)\n",
    "- [Voir site de données ouvertes (souvent anglophones)](https://github.com/awesomedata/awesome-public-datasets)\n",
    "\n",
    "---\n",
    "- [Voir source du fichier de données des prénoms - Fichier que nous allons utiliser pour la suite du TP](https://www.insee.fr/fr/statistiques/2540004?sommaire=4767262#consulter)\n",
    "  - Pas besoin de télécharger l'archive contenant le csv par département depuis ce lien, un lien direct a été mis plus bas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comma-separated values ou csv est un format de fichier représentant des valeurs tabulaires sous forme de valeurs séparées par des virgules, ce caractère étant celui de séparation par défaut. Chaque valeur entre virgule représentant une cellule.\n",
    "\n",
    "![csv](_images/csv.jpg)\n",
    "- [En savoir plus sur le format csv (wikipedia)](https://fr.wikipedia.org/wiki/Comma-separated_values)\n",
    "\n",
    "Il est possible de transformer un fichier tableur (.xls, .xslx, .ods...) en fichier csv, il suffit juste à la sauvegarde de préciser le format csv. \n",
    "\n",
    "![sauvegarde-csv](_images/sauvegarde-csv.jpg)\n",
    "\n",
    "Néanmoins pandas est très polyvalent, il est possible d'importer un fichier excel (xls/xslx), un fichier sql ou encore un tableau HTML en provenance d'un site. Pour les fichiers excel (xls/xslx), il faudra préciser le classeur que l'on souhaite charger.\n",
    "\n",
    "- [Voir liste des types gérés par pandas](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le cadre de ce cours, nous allons principalement manipuler des fichiers csv et les charger grâce à la méthode `pd.read_csv(\"chemin-du-fichier.csv\")` de pandas. Il faudra importer pandas (`import pandas as pd`) avant d'appeler la méthode `read_csv()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pour les utilisateurs de Google colab\n",
    "\n",
    "Petit apparté pour les utilisateurs de google colab. Pour charger un fichier local, il faudra rajouter les lignes de codes suivantes :\n",
    "\n",
    "```python\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "import pandas as pd\n",
    "import io\n",
    "# Très important : le nom du fichier passé en paramètre de la fonction \"uploaded\" doit avoir le même nom que le fichier que vous avez uploadé sinon, \n",
    "# vous aurez forcément une erreur\n",
    "df = pd.read_csv(io.BytesIO(uploaded['nom-du-fichier-uploader.csv']))\n",
    "```\n",
    "- **Ces lignes doivent être avant la manipulation d'un DataFrame et de préférence dans une cellule dédiée pour éviter d'uploader votre fichier à chaque fois**\n",
    "- **Vous ne pouvez pas importer de fichiers en navigation privée**\n",
    "\n",
    "- [Voir plus d'informations sur le chargement de fichiers externes avec Google colab - anglais](https://towardsdatascience.com/3-ways-to-load-csv-files-into-colab-7c14fcbdcb92)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement d'un fichier distant\n",
    "\n",
    "Bien que nous fassions du Python depuis Jupyter, nous avons toujours accès aux méthodes et classes natives de Python dont \"request\". Elle nous permet d'effectuer des rêquetes serveurs et donc de charger des fichiers\n",
    "\n",
    "```python\n",
    "from urllib import request\n",
    "import pandas as pd\n",
    "\n",
    "request.urlretrieve(\"https://s3-eu-west-1.amazonaws.com/static.oc-static.com/prod/courses/files/Parcours_data_scientist/decouvrez-les-librairies-python-pour-la-data-science/hubble_data.csv\", \"hubble.csv\")\n",
    "hubble = pd.read_csv(\"hubble.csv\")\n",
    "```\n",
    "\n",
    "Le code ci-dessus est là à titre indicatif, nous n'aurons pas besoin d'utiliser des fichiers distants dans nos pratiques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 0 : Téléchargement du dataset\n",
    "- [Télécharger dataset des prénoms](https://github.com/DanYellow/cours/blob/main/big-data-s4/datasets/naissances-par-departement-1900-2020.zip) (Cliquez sur le bouton \"Télécharger / Download\" sur github)\n",
    "  - Décompressez l'archive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Petite note** : Le fichier possède plus de 3 500 000 lignes. Si on essaye d'ouvrir le fichier avec OpenOffice Calc (équivalent Open Source d'Excel), on a le droit au message suivant :\n",
    "\n",
    "![erreur chargement](_images/erreur-chargement-calc.jpg)\n",
    "\n",
    "Heureusement, nous utilisons pandas nous allons pouvoir ouvrir le fichier sans encombres.\n",
    "\n",
    "# Phase 1 : Récupération / Chargement du fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilisateurs de Google Colab\n",
    "# pensez bien à uploader le fichier dans cette cellule\n",
    "# avec le code plus haut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# On importe pandas, pas de pandas, pas de DataFrame donc pas de manipulation de données tabulaires\n",
    "import pandas as pd\n",
    "\n",
    "# On charge le fichier dans une cellule spécifique. Pourquoi ? On veut éviter de charger ce gros fichier régulièrement.\n",
    "# Si nous utilisez Google Colab, ça devrait aller plus vite.\n",
    "# Le premier paramètre de notre fonction est très important, c'est le chemin vers votre fichier, comme en HTML si vous \n",
    "# changez le nom du fichier, il faudra penser à éditer le chemin dans la méthode.\n",
    "liste_prenoms_source = pd.read_csv(\"A-REMPLACER\", sep=\";\") # le fichier est chargé en tant que DataFrame\n",
    "\n",
    "# La fonction \"read_csv\" possède plein de paramètres permettant la lecture d'un fichier csv beaucoup plus souple, on peut, par exemple, importer certaines colonnes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note importante sur les fichiers CSV\n",
    "\n",
    "Le csv que nous allons utiliser utilise des point-virgules ( ; ) pour séparer les colonnes d'où le paramètre `sep=\";\"` dans le code, il indique le séparateur des colonnes permettant ainsi d'afficher, de manipuler correctement notre DataFrame. Si le séparateur est incorrect, une erreur peut être levée ou le DataFrame sera consititué que d'une seule colonne (voir image ci-dessous).\n",
    "\n",
    "![mauvais séparateur de colonnes](_images/dataframe-mauvais-separateur.png)\n",
    "\n",
    "Pensez à changer le caractère de séparation des cellules de votre csv en cas de problème."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2 : Exploration des données\n",
    "Après avoir chargé un DataFrame, la première chose à faire est de l'explorer. Cette phase nous permet de savoir assez facilement et rapidement quel jeu de données on manipule, on essaye de répondre aux questions suivantes pour mieux comprendre notre DataFrame :\n",
    "- A quoi ressemble notre DataFrame ? # `df.head()` ou `df.tail()` ou `display(df)` / `display(df)` équivaut à faire `df.head()` et `df.tail()` en même temps\n",
    "  - Ces méthodes vont afficher les 5 premières/dernières lignes, il est possible de passer un nombre en paramètre pour en afficher plus ou moins\n",
    "- Combien de lignes et colonnes possède-t-il ? # `df.shape`\n",
    "- Quel est le type de chaque champ ? # `df.dtypes`\n",
    "- Quels sont les noms des colonnes ? # `df.columns.values.tolist()`\n",
    "- Existe-il des données absentes ou nulles / Combien il y a de données absentes ou nulles ? # `df.isnull().any()` ou `df.isna().any()` / `df.isnull().sum()` ou `df.isna().sum()`\n",
    "- Quelles données statistiques ressortent de mon jeu de données ? # `df.describe()`\n",
    "- Combien de valeurs uniques existe-t-il ? # `df.value_counts()`\n",
    "- Quelle est valeur min/max de certaines colonnes ? # `df['colonne'].min()/.max()`\n",
    "- Combien d'espace mémoire consomme mon DataFrame ? # `df.info()`\n",
    "- Combien de valeurs uniques existe-t-il par colonne ? / Quelles sont ces valeurs uniques ? # `df.nunique()` / `df[\"nom_du_champ\"].unique()`\n",
    "  - Attention concernant `df[\"nom_du_champ\"].unique()`, si vous avez beaucoup de valeurs uniques jupyter risque de ne pas tout afficher\n",
    "  - Écrire `df[\"nom_du_champ\"].unique()` pour chaque champ peut être fastideux, ainsi il est possible d'écrire à la place `pd.Series({colonne: df[colonne].unique() for colonne in df})`. Ceci affichera toutes les valeurs uniques pour chaque champs\n",
    "\n",
    "`.values.tolist()` a été rajouté pour s'assurer que toutes les lignes soient affichées dans Jupyter, l'outil ayant tendance à tronquer l'affichage quand il y a trop de résultats.\n",
    "\n",
    "Il n'est pas utile de répondre à toutes ces questions, toutefois, il faut au moins répondre aux questions suivantes : \n",
    "- A quoi ressemble notre DataFrame ?\n",
    "  - Quels sont les noms des colonnes ?\n",
    "  - Combien de lignes/colonnes possède-t-il ?\n",
    "- Existe-il des données absentes / nulles ?\n",
    "\n",
    "Ces quatre questions nous aideront beaucoup pour la phase suivante, mais répondre à plus de questions pourra encore plus nous aider.\n",
    "\n",
    "## A vous de coder\n",
    "Répondre en code aux questions posées plus haut, inutile de stocker ceci dans une variable, utilisez simplement la fonction `display()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codez ici - N'hésitez pas à rajouter des cellules de travail pour rendre le tout plus lisible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qu'observez-vous ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combien d'espace mémoire (RAM) consomme mon DataFrame ? # `df.info()`\n",
    "\n",
    "Si vous avez déjà développé dans un langage où la gestion de mémoire à son importance (comme le C ou C++), vous avez vu que le typage des variables avait son importance quant à la place prise dans l'espace mémoire (RAM) de l'appareil. Ainsi un nombre entier n'occupera pas la même place qu'un nombre décimal et mal typer les variables peut avoir des conséquences sur les performances d'une application, ceci pouvant même conduire à un crash.\n",
    "Nous avons vu précémment qu'il n'était pas utile de typer les variables en Python toutefois, ceci ne veut pas dire que c'était impossible de le faire. Avec les DataFrame, pandas (et Python par extension) devinne le type des champs, cette opération consomme de la mémoire. Bien que pandas soit bien optimisé, il est possible d'alléger sa charge de travail en indiquant explicitement le type des champs. Par exemple :\n",
    "\n",
    "```python\n",
    "pd.read_csv(\"fromages.csv\", dtype={\n",
    "    \"nom\": \"str\", # str pour \"string\" soit \"chaîne de caractères\"\n",
    "    \"type_de_lait\": \"str\",\n",
    "    \"mois_affinage\": \"uint8\", # uint8 pour \"unsigned integer 8bits\" soit \"entier strictement positif sur 8bits\"\n",
    "    \"prix\": \"uint8\",\n",
    "    \"dpt_origine\": \"str\",\n",
    "})\n",
    "```\n",
    "En précisant le paramètre dtype (**facultatif**), on aide pandas à consommer moins de RAM. Regardez le notebook \"performances-types.ipynb\" (présent dans la ressource) pour en savoir plus.\n",
    "\n",
    "On peut également alléger la consommation en RAM de notre notebook grâce à la méthode globale `del` qui nous permet de supprimer un DataFrame quand nous n'en avons plus besoin\n",
    "```python\n",
    "del df_inutile_maintenant\n",
    "```\n",
    "\n",
    "**Ceci est à titre indicatif, ce n'est pas obligatoire de le faire**. Par ailleurs, le typage des colonnes aura plus son importance sur les gros jeux de données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pourquoi les index ?\n",
    "\n",
    "Dans la précédente partie, nous avons vu qu'il était possible de définir des index dans un DataFrame, une fois défini, nous avions accès à la syntaxe `df.loc['mon_index']`. **Il faut comprendre que la définition de l'index a une importance quant aux performances de pandas.** Prenons le cas suivant : Nous souhaitons chercher toutes les occurences du prénom \"Pauline\" dans notre DataFrame. Nous pouvons écrire le code suivant.\n",
    "```python\n",
    "    liste_prenoms_source[liste_prenoms_source['preusuel'] == \"PAULINE\"]\n",
    "```\n",
    "Ou nous pouvons définir la colonne \"preusuel\" en tant qu'index puis faire une rechercher grâce à la propriété \".loc\".\n",
    "```python\n",
    "    liste_prenoms_source.set_index(\"preusuel\").loc['PAULINE']\n",
    "    # Note : L'opération \"set_index\" est coûteuse en terme de temps d'exécution\n",
    "```\n",
    "Comparons les deux instructions (il est possible d'exécuter plusieurs cellules en même temps). L'opération `set_index` étant coûteuse, on va effectuer trois tests et calculer le temps d'exécution :\n",
    "- La recherche du prénom \"PAULINE\" sans index\n",
    "- La recherche du prénom \"PAULINE\" avec la colonne \"preusuel\" indexée + indexation de la colonne \"preusuel\"\n",
    "- La recherche du prénom \"PAULINE\" avec la colonne \"preusuel\" indexée\n",
    "\n",
    "Il est également possible d'utiliser des index multiples pour hiérarchiser vos données. Ou encore que par défaut, l'index est une série de nombre qui commence à 0.\n",
    "\n",
    "- [Plus de détails concernant les index des DataFrame](https://www.sharpsightlabs.com/blog/pandas-index/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236 ms ± 2.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit liste_prenoms_source[liste_prenoms_source['preusuel'] == \"PAULINE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "421 ms ± 9.83 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit liste_prenoms_source.set_index(\"preusuel\").loc['PAULINE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.4 ms ± 1.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "preusuel_index = liste_prenoms_source.set_index(\"preusuel\")\n",
    "%timeit preusuel_index.loc['PAULINE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quels résultats observez-vous ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commandes magiques\n",
    "\n",
    "Vous avez remarqué que dans les cellules précédentes, nous avons utilisé `%timeit`, cette syntaxe est propre à jupyter, on appelle ceci une commande magique. Elles ajoutent de nouvelles fonctionnalités aux notebooks de façon très simple, ces fonctionnalités peuvent s'appliquer sur **une seule ligne de code** comme le code ci-dessous.\n",
    "\n",
    "```python\n",
    "%ma_commande_magique mon_code_python\n",
    "```\n",
    "\n",
    "ou du code sur plusieurs lignes (remarquez bien la présence double du signe pourcentage `%%`).\n",
    "\n",
    "```python\n",
    "%%ma_commande_magique \n",
    "mon_code_python\n",
    "```\n",
    "Dans le cas ci-dessus la commande magique s'applique sur toute la cellule. Ainsi le code de la première cellule contenant `%timeit` aurait pu être écrit de de la façon suivante.\n",
    "\n",
    "\n",
    "```python\n",
    "%%timeit \n",
    "liste_prenoms_source[liste_prenoms_source['preusuel'] == \"PAULINE\"]\n",
    "```\n",
    "\n",
    "**Attention :** Toutes les commandes magiques ne sont pas elligibles à la gestion multilignes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IPython -- An enhanced Interactive Python - Quick Reference Card\n",
      "================================================================\n",
      "\n",
      "obj?, obj??      : Get help, or more help for object (also works as\n",
      "                   ?obj, ??obj).\n",
      "?foo.*abc*       : List names in 'foo' containing 'abc' in them.\n",
      "%magic           : Information about IPython's 'magic' % functions.\n",
      "\n",
      "Magic functions are prefixed by % or %%, and typically take their arguments\n",
      "without parentheses, quotes or even commas for convenience.  Line magics take a\n",
      "single % and cell magics are prefixed with two %%.\n",
      "\n",
      "Example magic function calls:\n",
      "\n",
      "%alias d ls -F   : 'd' is now an alias for 'ls -F'\n",
      "alias d ls -F    : Works if 'alias' not a python name\n",
      "alist = %alias   : Get list of aliases to 'alist'\n",
      "cd /usr/share    : Obvious. cd -<tab> to choose from visited dirs.\n",
      "%cd??            : See help AND source for magic %cd\n",
      "%timeit x=10     : time the 'x=10' statement with high precision.\n",
      "%%timeit x=2**100\n",
      "x**100           : time 'x**100' with a setup of 'x=2**100'; setup code is not\n",
      "                   counted.  This is an example of a cell magic.\n",
      "\n",
      "System commands:\n",
      "\n",
      "!cp a.txt b/     : System command escape, calls os.system()\n",
      "cp a.txt b/      : after %rehashx, most system commands work without !\n",
      "cp ${f}.txt $bar : Variable expansion in magics and system commands\n",
      "files = !ls /usr : Capture system command output\n",
      "files.s, files.l, files.n: \"a b c\", ['a','b','c'], 'a\\nb\\nc'\n",
      "\n",
      "History:\n",
      "\n",
      "_i, _ii, _iii    : Previous, next previous, next next previous input\n",
      "_i4, _ih[2:5]    : Input history line 4, lines 2-4\n",
      "exec(_i81)       : Execute input history line #81 again\n",
      "%rep 81          : Edit input history line #81\n",
      "_, __, ___       : previous, next previous, next next previous output\n",
      "_dh              : Directory history\n",
      "_oh              : Output history\n",
      "%hist            : Command history of current session.\n",
      "%hist -g foo     : Search command history of (almost) all sessions for 'foo'.\n",
      "%hist -g         : Command history of (almost) all sessions.\n",
      "%hist 1/2-8      : Command history containing lines 2-8 of session 1.\n",
      "%hist 1/ ~2/     : Command history of session 1 and 2 sessions before current.\n",
      "%hist ~8/1-~6/5  : Command history from line 1 of 8 sessions ago to\n",
      "                   line 5 of 6 sessions ago.\n",
      "%edit 0/         : Open editor to execute code with history of current session.\n",
      "\n",
      "Autocall:\n",
      "\n",
      "f 1,2            : f(1,2)  # Off by default, enable with %autocall magic.\n",
      "/f 1,2           : f(1,2) (forced autoparen)\n",
      ",f 1 2           : f(\"1\",\"2\")\n",
      ";f 1 2           : f(\"1 2\")\n",
      "\n",
      "Remember: TAB completion works in many contexts, not just file names\n",
      "or python names.\n",
      "\n",
      "The following magic functions are currently available:\n",
      "\n",
      "%alias:\n",
      "    Define an alias for a system command.\n",
      "%alias_magic:\n",
      "    ::\n",
      "%autoawait:\n",
      "    \n",
      "%autocall:\n",
      "    Make functions callable without having to type parentheses.\n",
      "%automagic:\n",
      "    Make magic functions callable without having to type the initial %.\n",
      "%autosave:\n",
      "    Set the autosave interval in the notebook (in seconds).\n",
      "%bookmark:\n",
      "    Manage IPython's bookmark system.\n",
      "%cd:\n",
      "    Change the current working directory.\n",
      "%clear:\n",
      "    Clear the terminal.\n",
      "%cls:\n",
      "    Clear the terminal.\n",
      "%colors:\n",
      "    Switch color scheme for prompts, info system and exception handlers.\n",
      "%conda:\n",
      "    Run the conda package manager within the current kernel.\n",
      "%config:\n",
      "    configure IPython\n",
      "%connect_info:\n",
      "    Print information for connecting other clients to this kernel\n",
      "%copy:\n",
      "    Alias for `!copy`\n",
      "%ddir:\n",
      "    Alias for `!dir /ad /on`\n",
      "%debug:\n",
      "    ::\n",
      "%dhist:\n",
      "    Print your history of visited directories.\n",
      "%dirs:\n",
      "    Return the current directory stack.\n",
      "%doctest_mode:\n",
      "    Toggle doctest mode on and off.\n",
      "%echo:\n",
      "    Alias for `!echo`\n",
      "%ed:\n",
      "    Alias for `%edit`.\n",
      "%edit:\n",
      "    Bring up an editor and execute the resulting code.\n",
      "%env:\n",
      "    Get, set, or list environment variables.\n",
      "%gui:\n",
      "    Enable or disable IPython GUI event loop integration.\n",
      "%hist:\n",
      "    Alias for `%history`.\n",
      "%history:\n",
      "    ::\n",
      "%killbgscripts:\n",
      "    Kill all BG processes started by %%script and its family.\n",
      "%ldir:\n",
      "    Alias for `!dir /ad /on`\n",
      "%less:\n",
      "    Show a file through the pager.\n",
      "%load:\n",
      "    Load code into the current frontend.\n",
      "%load_ext:\n",
      "    Load an IPython extension by its module name.\n",
      "%loadpy:\n",
      "    Alias of `%load`\n",
      "%logoff:\n",
      "    Temporarily stop logging.\n",
      "%logon:\n",
      "    Restart logging.\n",
      "%logstart:\n",
      "    Start logging anywhere in a session.\n",
      "%logstate:\n",
      "    Print the status of the logging system.\n",
      "%logstop:\n",
      "    Fully stop logging and close log file.\n",
      "%ls:\n",
      "    Alias for `!dir /on`\n",
      "%lsmagic:\n",
      "    List currently available magic functions.\n",
      "%macro:\n",
      "    Define a macro for future re-execution. It accepts ranges of history,\n",
      "%magic:\n",
      "    Print information about the magic function system.\n",
      "%matplotlib:\n",
      "    ::\n",
      "%mkdir:\n",
      "    Alias for `!mkdir`\n",
      "%more:\n",
      "    Show a file through the pager.\n",
      "%notebook:\n",
      "    ::\n",
      "%page:\n",
      "    Pretty print the object and display it through a pager.\n",
      "%pastebin:\n",
      "    Upload code to dpaste.com, returning the URL.\n",
      "%pdb:\n",
      "    Control the automatic calling of the pdb interactive debugger.\n",
      "%pdef:\n",
      "    Print the call signature for any callable object.\n",
      "%pdoc:\n",
      "    Print the docstring for an object.\n",
      "%pfile:\n",
      "    Print (or run through pager) the file where an object is defined.\n",
      "%pinfo:\n",
      "    Provide detailed information about an object.\n",
      "%pinfo2:\n",
      "    Provide extra detailed information about an object.\n",
      "%pip:\n",
      "    Run the pip package manager within the current kernel.\n",
      "%popd:\n",
      "    Change to directory popped off the top of the stack.\n",
      "%pprint:\n",
      "    Toggle pretty printing on/off.\n",
      "%precision:\n",
      "    Set floating point precision for pretty printing.\n",
      "%prun:\n",
      "    Run a statement through the python code profiler.\n",
      "%psearch:\n",
      "    Search for object in namespaces by wildcard.\n",
      "%psource:\n",
      "    Print (or run through pager) the source code for an object.\n",
      "%pushd:\n",
      "    Place the current dir on stack and change directory.\n",
      "%pwd:\n",
      "    Return the current working directory path.\n",
      "%pycat:\n",
      "    Show a syntax-highlighted file through a pager.\n",
      "%pylab:\n",
      "    ::\n",
      "%qtconsole:\n",
      "    Open a qtconsole connected to this kernel.\n",
      "%quickref:\n",
      "    Show a quick reference sheet \n",
      "%recall:\n",
      "    Repeat a command, or get command to input line for editing.\n",
      "%rehashx:\n",
      "    Update the alias table with all executable files in $PATH.\n",
      "%reload_ext:\n",
      "    Reload an IPython extension by its module name.\n",
      "%ren:\n",
      "    Alias for `!ren`\n",
      "%rep:\n",
      "    Alias for `%recall`.\n",
      "%rerun:\n",
      "    Re-run previous input\n",
      "%reset:\n",
      "    Resets the namespace by removing all names defined by the user, if\n",
      "%reset_selective:\n",
      "    Resets the namespace by removing names defined by the user.\n",
      "%rmdir:\n",
      "    Alias for `!rmdir`\n",
      "%run:\n",
      "    Run the named file inside IPython as a program.\n",
      "%save:\n",
      "    Save a set of lines or a macro to a given filename.\n",
      "%sc:\n",
      "    Shell capture - run shell command and capture output (DEPRECATED use !).\n",
      "%set_env:\n",
      "    Set environment variables.  Assumptions are that either \"val\" is a\n",
      "%store:\n",
      "    Lightweight persistence for python variables.\n",
      "%sx:\n",
      "    Shell execute - run shell command and capture output (!! is short-hand).\n",
      "%system:\n",
      "    Shell execute - run shell command and capture output (!! is short-hand).\n",
      "%tb:\n",
      "    Print the last traceback.\n",
      "%time:\n",
      "    Time execution of a Python statement or expression.\n",
      "%timeit:\n",
      "    Time execution of a Python statement or expression\n",
      "%unalias:\n",
      "    Remove an alias\n",
      "%unload_ext:\n",
      "    Unload an IPython extension by its module name.\n",
      "%who:\n",
      "    Print all interactive variables, with some minimal formatting.\n",
      "%who_ls:\n",
      "    Return a sorted list of all interactive variables.\n",
      "%whos:\n",
      "    Like %who, but gives some extra information about each variable.\n",
      "%xdel:\n",
      "    Delete a variable, trying to clear it from anywhere that\n",
      "%xmode:\n",
      "    Switch modes for the exception handlers.\n",
      "%%!:\n",
      "    Shell execute - run shell command and capture output (!! is short-hand).\n",
      "%%HTML:\n",
      "    Alias for `%%html`.\n",
      "%%SVG:\n",
      "    Alias for `%%svg`.\n",
      "%%bash:\n",
      "    %%bash script magic\n",
      "%%capture:\n",
      "    ::\n",
      "%%cmd:\n",
      "    %%cmd script magic\n",
      "%%debug:\n",
      "    ::\n",
      "%%file:\n",
      "    Alias for `%%writefile`.\n",
      "%%html:\n",
      "    ::\n",
      "%%javascript:\n",
      "    Run the cell block of Javascript code\n",
      "%%js:\n",
      "    Run the cell block of Javascript code\n",
      "%%latex:\n",
      "    Render the cell as a block of latex\n",
      "%%markdown:\n",
      "    Render the cell as Markdown text block\n",
      "%%perl:\n",
      "    %%perl script magic\n",
      "%%prun:\n",
      "    Run a statement through the python code profiler.\n",
      "%%pypy:\n",
      "    %%pypy script magic\n",
      "%%python:\n",
      "    %%python script magic\n",
      "%%python2:\n",
      "    %%python2 script magic\n",
      "%%python3:\n",
      "    %%python3 script magic\n",
      "%%ruby:\n",
      "    %%ruby script magic\n",
      "%%script:\n",
      "    ::\n",
      "%%sh:\n",
      "    %%sh script magic\n",
      "%%svg:\n",
      "    Render the cell as an SVG literal\n",
      "%%sx:\n",
      "    Shell execute - run shell command and capture output (!! is short-hand).\n",
      "%%system:\n",
      "    Shell execute - run shell command and capture output (!! is short-hand).\n",
      "%%time:\n",
      "    Time execution of a Python statement or expression.\n",
      "%%timeit:\n",
      "    Time execution of a Python statement or expression\n",
      "%%writefile:\n",
      "    ::\n"
     ]
    }
   ],
   "source": [
    "# Il est possible de lister les commandes magiques avec la commande : %lsmagic\n",
    "%lsmagic\n",
    "\n",
    "# la commande %quickref affiche la documention des commandes\n",
    "%quickref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3 : Nettoyage de données\n",
    "\n",
    "Le nettoyage de données consiste à supprimer/modifier les mauvaises de données, elles peuvent être de plusieurs formes : \n",
    "- Une donnée manquante\n",
    "- Des données dupliquées\n",
    "- Une donnée au mauvais format\n",
    "- Une donnée incorrecte\n",
    "\n",
    "Il est préférable de nettoyer les données pour plusieurs raisons :\n",
    "- Eviter les problèmes de calculs (données manquantes / données aberrantes = résultat incorrect)\n",
    "- Eviter les affichages étranges de graphiques\n",
    "- Uniformiser les données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Le code ci-dessous remplace toutes les prénoms dans la colonne \"preusuel\" avec leur équivalent sans accents\n",
    "df[\"preusuel\"] = df[\"preusuel\"].apply(lambda x: unidecode(x, \"utf-8\")) \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemples de code pour nettoyer les données\n",
    "\n",
    "**Permet de supprimer lignes avec des données absentes**\n",
    "\n",
    "Le paramètre \"inplace\" permet de faire muter le dataframe quand le paramètre est égale à \"True\", inplace=False renvoie un nouveau dataframe\n",
    "```python \n",
    "df.dropna(inplace = True)\n",
    "```\n",
    "\n",
    "**Permet de supprimer lignes avec des données non conformes aux conditions définies**\n",
    "\n",
    "**Renvoie** un nouveau DataFrame.\n",
    "```python \n",
    "df.drop(df[<nos conditions>].index)\n",
    "```\n",
    "\n",
    "**Permet de supprimer lignes avec des données dupliquées**\n",
    "\n",
    "**Ne renvoie pas** un nouveau DataFrame.\n",
    "```python \n",
    "df.drop_duplicates(inplace = True)\n",
    "```\n",
    "\n",
    "**Permet de remplir les cases vides d'une serie, par la valeur moyenne de la serie**\n",
    "\n",
    "La fonction retourne un nouveau dataframe, toutefois, il est possible de faire muter le dataframe en rajoutant le paramètre \"inplace = True\"\n",
    "```python \n",
    "df['nom_de_la_colonne'].fillna(df['nom_de_la_colonne'].mean())\n",
    "```\n",
    "\n",
    "**Permet de changer le type d'une colonne**\n",
    "\n",
    "Ceci peut permettre, notamment de diminuer/augmenter la taille en mémoire d'un dataset (`df.info(memory_usage='deep')`)\n",
    "```python \n",
    "df['nom_de_la_colonne'] = df['nom_de_la_colonne'].astype(nom_du_type)\n",
    "```\n",
    "- [Voir liste des types - Documentation numpy](https://numpy.org/doc/stable/reference/arrays.dtypes.html)\n",
    "\n",
    "**Permet d'appliquer une fonction sur une colonne (ne pas oublier de retourner la valeur)**\n",
    "```python\n",
    "def ma_fonction(val):\n",
    "    return val + 2\n",
    "df['nom_de_la_colonne'] = df['nom_de_la_colonne'].apply(ma_fonction)\n",
    "```\n",
    "\n",
    "Note : si la fonction est un simple calcul, il est possible d'appliquer sur la même ligne le calcul comme le code suivant :\n",
    "```python\n",
    "# Divise toutes les valeurs de la colonne par 2\n",
    "df['nom_de_la_colonne'] = df['nom_de_la_colonne'] / 2\n",
    "\n",
    "# ATTENTION : Il est préférable de s'assurer que sa série est bien numérique avant d'appliquer une opération arithmétique sinon pandas lèvera une erreur à coup sûr.\n",
    "```\n",
    "\n",
    "**Permet de filtrer les lignes par condition (& pour \"et\", | pour \"ou\")**\n",
    "```python\n",
    "df[(df[\"nom_de_la_colonne_1\"] == \"valeur\") | (df[\"nom_de_la_colonne_2\"] == \"valeur\")]\n",
    "```\n",
    "Condition plus complexe \n",
    "```python\n",
    "df[\n",
    "    ((df[\"nom_de_la_colonne_1\"] == \"valeur\") | (df[\"nom_de_la_colonne_2\"] == \"valeur\")) &\n",
    "    (df[\"nom_de_la_colonne_3\"] == \"valeur\")\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nettoyez vos données ici... mais avant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kévin, Kevin, Elise ou Élise ?\n",
    "\n",
    "Comme expliqué précédemment, le nettoyage des données est une étape importante pour s'assurer de travailler avec des données saines. Dans le cas des prénoms, on peut être face à des problèmes liés aux accents. Si les prénoms \"Kévin\" et \"Kevin\" représentent le même prénom et sont prononcés de la même façon pour un être humain, pour un ordinateur ce n'est pas la même. Ainsi, il est indispensable de substituer toutes les lettres avec accents avec leurs équivalents sans accents. De ce fait, on obtiendra tous les \"Kevin\" (accent ou non) de notre document. Avec Pandas, on le fait avec le code suivant :\n",
    "\n",
    "```python\n",
    "# Le code ci-dessous remplace toutes les prénoms dans la colonne \"preusuel\" avec leur équivalent sans accents\n",
    "df[\"preusuel\"] = df[\"preusuel\"].apply(lambda x: unidecode(x, \"utf-8\")) \n",
    "```\n",
    "Cette logique s'applique également aux majuscules. Sauf cas précis, il est préférable de faire des comparaisons de chaînes de caractères avec la même casse. Avec Pandas, on transformera la casse d'une Serie grâce à la méthode `.str.lower()`. Exemple :\n",
    "\n",
    "```python\n",
    "# On compare la colonne \"key\" qu'on a passé en minuscule avec la valeur \"value\" elle-même passée en minuscules\n",
    "df_result = df[(df[\"key\"].str.lower() != value.lower())]\n",
    "```\n",
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lorsqu'on applique des opérations sur un DataFrame, il est souvent préférable de travailler à partir d'une copie. En effet, durant cette phase de nettoyage nous allons être amené à supprimer des lignes ou encore altérer des valeurs directement sur le DataFrame (paramètre `inplace=true`), mais que ce passe-t-il si nous trompons dans nos opérations ? Nous sommes obligés de compiler toutes les cellules depuis le début, fastidieux et ça prend beaucoup de temps si le jeu de données original est très lourd.\n",
    "\n",
    "De ce fait, durant cette phase de nettoyage, deux options s'offrent à nous :\n",
    "- Ne pas utiliser le paramètre `inplace=true` et mettre les résultats dans des variables différentes\n",
    "- Faire une copie du DataFrame originel grâce à la méthode `.copy()`. Par exemple :\n",
    "```python\n",
    "df_copy = df.copy()\n",
    "# Application de modifications\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'liste_prenoms_source' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-6fe563a8db2b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Nettoyez vos données ici avec le DataFrame prenoms_nettoyage, nous allons utiliser la technique de la copie\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprenoms_nettoyage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mliste_prenoms_source\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Pour les années, pour être sûr que toutes les valeurs sont des années,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# nous allons faire un filtre pour retirer toutes les lignes dont la valeur pour\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'liste_prenoms_source' is not defined"
     ]
    }
   ],
   "source": [
    "# Nettoyez vos données ici avec le DataFrame prenoms_nettoyage, nous allons utiliser la technique de la copie\n",
    "prenoms_nettoyage = liste_prenoms_source.copy()\n",
    "\n",
    "# Pour les années, pour être sûr que toutes les valeurs sont des années, \n",
    "# nous allons faire un filtre pour retirer toutes les lignes dont la valeur pour\n",
    "# pour la colonne \"annais\" n'est pas numérique. \n",
    "# C'est ce que fait la ligne suivante en appliquant un masque sur la colonne \"annais\" :\n",
    "\n",
    "prenoms_nettoyage = prenoms_nettoyage[prenoms_nettoyage[\"annais\"].str.isnumeric() == True]\n",
    "\n",
    "# Toutefois, dépendamment des questions auxquelles vous voulez répondre \n",
    "# le filtre précédent peut être inutile et donc être commenté"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A vous de coder\n",
    "\n",
    "A partir du DataFrame des prénoms, définir des DataFrame correspondants aux critères suivants (une ligne, un nouveau DataFrame) :\n",
    "\n",
    "1. Contient 10 000 premières entrées concernant les naissances d'enfants de sexe féminin dans toute la France\n",
    "   - 1 = garçon | 2 = fille \n",
    "2. Contient toutes les naissances d'enfants ayant votre prénom dans toute la France\n",
    "3. Contient toutes les naissances de l'année de votre naissance dans le département de votre choix\n",
    "4. Contient toutes les naissances de l'année de votre naissance dans la région de votre choix (plusieurs départements) \n",
    "  - Le DataFrame final doit contenir une colonne contenant le nom de la région\n",
    "5. Contient toutes les naissances de l'année de votre naissance, dix avant et après votre naissance dans toute la France\n",
    "\n",
    "N'oubliez pas que la syntaxe Python vu précédemment fonctionne également avec pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Groupons-les - Suite\n",
    "\n",
    "Dans la partie précédente, nous avons vu qu'il était possible de grouper nos DataFrame selon un ou plusieurs colonnes. Ceci étant pratique pour récupérer un aggrégat de certaines colonnes.\n",
    "Toutefois que devons-nous faire lorsque nous souhaitons récupérer les N premiers / derniers lignes de chaque groupe ? Encore une fois un groupe. Prenons la question suivante : \"Quels sont les 5 prénoms les moins populaires des trois années (de votre choix) du sexe féminin ?\". Pour se faire, il faudra procéder de la façon suivante :\n",
    "\n",
    "```python\n",
    "top_n_derniers_prenoms = (\n",
    "    prenoms_nettoyage[prenoms_nettoyage[\"sexe\"] == 2]\n",
    "        .groupby(['preusuel', 'annais']) # On groupe par series \"preusuel\" et \"annais\"\n",
    "        .sum() # On fait la somme sur les series numériques\n",
    "        .apply(lambda grp: grp.nsmallest(15, \"nombre\")) # On retourne les 15 derniers résultats\n",
    ")\n",
    "# On réinitialise les colonnes ensuite\n",
    "top_n_derniers_prenoms.reset_index(drop=True, inplace=True)\n",
    "```\n",
    "\n",
    "Essayez ce code dans la cellule de code suivante.\n",
    "\n",
    "Le code ci-dessus utilise des parenthèses pour permettre l'écriture d'instructions multilignes,dedans on peut donc faire des retours à la ligne et donc rendre nos instructions plus claires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testez le code de la cellule précédente ici.\n",
    "# Note : vous êtes bien évidemment invité à modifier le code pour mieux vous approprier le sujet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le résultat obtenu peut également être ordonné grâce à la méthode `sort_values()`. Exemple :\n",
    "\n",
    "```python\n",
    "top_n_premiers_prenoms = (\n",
    "    prenoms_nettoyage[prenoms_nettoyage[\"sexe\"] == 2]\n",
    "        .groupby(['preusuel', 'annais'])\n",
    "        .sum()\n",
    "        # Ici on change, on ne prend plus les 15 derniers, mais les 15 premiers\n",
    "        .apply(lambda grp: grp.nsmallest(15, \"nombre\"))\n",
    ")\n",
    "\n",
    "# On ordonne avec les deux colonnes passées en paramètre et de façon descendante\n",
    "top_n_premiers_prenoms.sort_values(by=['annais'], ascending=False, inplace=True)\n",
    "top_n_premiers_prenoms.reset_index(drop=True, inplace=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En analyse de données, notre but est de se poser des questions (ou recevoir des questions de l'équipe produit) et bien évidemment d'y répondre grâce à la donnée, pour enfin en conclure quelque chose. N'oubliez pas _qu'un problème bien posé est à moitié résolu_. Ce sont des questions qui vont piloter vos DataFrame, votre code, vos articles.\n",
    "\n",
    "# A vous de coder\n",
    "\n",
    "A partir du DataFrame des prénoms, répondre aux questions suivantes avec une variable ou un DataFrame :\n",
    "1. Quel est le prénom masculin et féminin le plus populaire de l'année 1995 dans la France entière (Territoire d'Outre-Mer + Metropole) ?\n",
    "   - Quelle part de naissances représentent ces prénoms sur la totalité des naissances de 1995 ? \n",
    "2. Combien de naissances ont lieu en moyenne par département ?\n",
    "   - Il faudra donc grouper par département et appliquer la méthode `.mean()` \n",
    "3. Posez-vous une question, essayez d'y répondre avec vos connaissances de pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre question, essayez d'y répondre avec vos connaissances de pandas (A REMPLACER par votre question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporter vos DataFrame\n",
    "\n",
    "Avant de terminer, vous avez dû remarquer que consulter vos DataFrame dans Jupyter n'est pas forcément des plus pratiques notamment à cause de la troncature du rendu final. Heureusement pour vous, pandas permet d'exporter vos DataFrame sous plusieurs formats via des méthodes dédiées : .csv (to_csv), .xslx (to_excel) ou encore .sql (to_sql). \n",
    "```python\n",
    "# Ceci nous permet de créer un csv nommé \"mon-csv.csv\"\n",
    "df.to_csv(\"mon-csv.csv\")\n",
    "```\n",
    "\n",
    "A noter que si le fichier que vous êtes en train de créer est ouvert dans un autre logiciel, l'écriture du fichier risque d'échouer.\n",
    "- [Voir documentation de la méthode \"to_csv\"](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html?highlight=to_csv#)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ed06d07b9ff369db6ed7b53447be18709da67cd911d838d72fee7fecb26667a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
